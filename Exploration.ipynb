{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('./stores_sales_forecasting.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Row ID', 'Order ID', 'Order Date', 'Ship Date', 'Ship Mode',\n",
      "       'Customer ID', 'Customer Name', 'Segment', 'Country', 'City', 'State',\n",
      "       'Postal Code', 'Region', 'Product ID', 'Category', 'Sub-Category',\n",
      "       'Product Name', 'Sales', 'Quantity', 'Discount', 'Profit'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "colomns = dataframe.columns\n",
    "print(colomns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai remarqué que les données sont une jointure sur 3 tables. Donc j'ai séparé pour avoir une meilleur compréhension des données.\n",
    "J'inclus les colonnes Sales, Quantity, Discount, Profit dans tout les dataframe pour les étudier sur ses variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order_dataframe = dataframe[['Row ID', 'Order ID', 'Order Date', 'Ship Date', 'Ship Mode', 'Sales', 'Quantity', 'Discount', 'Profit']]\n",
    "Customer_dataframe = dataframe[['Row ID','Customer ID', 'Customer Name', 'Segment', 'Country', 'City', 'State', 'Postal Code', 'Region', 'Sales', 'Quantity', 'Discount', 'Profit']]\n",
    "Product_dataframe = dataframe[['Row ID','Product ID', 'Category', 'Sub-Category', 'Product Name', 'Sales', 'Quantity', 'Discount', 'Profit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Furniture']\n"
     ]
    }
   ],
   "source": [
    "distinct_categories = Product_dataframe['Category'].unique()\n",
    "print(distinct_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "Product_dataframe = Product_dataframe.drop(columns=['Category'])\n",
    "dataframe = dataframe.drop(columns=['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bookcases' 'Chairs' 'Tables' 'Furnishings']\n"
     ]
    }
   ],
   "source": [
    "unique_sub_categories = Product_dataframe['Sub-Category'].unique()\n",
    "print(unique_sub_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étude des catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-Category\n",
      "Bookcases       868\n",
      "Chairs         2356\n",
      "Furnishings    3563\n",
      "Tables         1241\n",
      "Name: Quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "quantity_per_sub_category = Product_dataframe.groupby('Sub-Category')['Quantity'].sum()\n",
    "print(quantity_per_sub_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-Category\n",
      "Bookcases      -3472.5560\n",
      "Chairs         26590.1663\n",
      "Furnishings    13059.1436\n",
      "Tables        -17725.4811\n",
      "Name: Profit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "profit_per_sub_category = Product_dataframe.groupby('Sub-Category')['Profit'].sum()\n",
    "print(profit_per_sub_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-Category\n",
      "Bookcases      0.211140\n",
      "Chairs         0.170178\n",
      "Furnishings    0.138349\n",
      "Tables         0.261285\n",
      "Name: Discount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "highest_discount_sub_category = Product_dataframe.groupby('Sub-Category')['Discount'].mean()\n",
    "print(highest_discount_sub_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bookcases and Tables have the highest discount rates and thus, which could explain the negative profit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Second Class' 'Standard Class' 'First Class' 'Same Day']\n"
     ]
    }
   ],
   "source": [
    "unique_ship_modes = Order_dataframe['Ship Mode'].unique()\n",
    "print(unique_ship_modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "Order_dataframe['Order Date'] = pd.to_datetime(Order_dataframe['Order Date'])\n",
    "Order_dataframe['Ship Date'] = pd.to_datetime(Order_dataframe['Ship Date'])\n",
    "\n",
    "dataframe['Order Date'] = pd.to_datetime(dataframe['Order Date'])\n",
    "dataframe['Ship Date'] = pd.to_datetime(dataframe['Ship Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ship Mode\n",
      "First Class       1238\n",
      "Same Day           453\n",
      "Second Class      1569\n",
      "Standard Class    4768\n",
      "Name: Quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "quantity_per_ship_mode = Order_dataframe.groupby('Ship Mode')['Quantity'].sum()\n",
    "print(quantity_per_ship_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ship Mode\n",
      "First Class        3066.9474\n",
      "Same Day            797.3484\n",
      "Second Class       4226.2614\n",
      "Standard Class    10360.7156\n",
      "Name: Profit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "profit_per_ship_mode = Order_dataframe.groupby('Ship Mode')['Profit'].sum()\n",
    "most_profitable_ship_mode = profit_per_ship_mode\n",
    "print(most_profitable_ship_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important month for orders is: Order Month\n",
      "1      81\n",
      "2      63\n",
      "3     140\n",
      "4     138\n",
      "5     150\n",
      "6     145\n",
      "7     164\n",
      "8     124\n",
      "9     282\n",
      "10    187\n",
      "11    319\n",
      "12    328\n",
      "Name: Order ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract month from Order Date\n",
    "Order_dataframe['Order Month'] = Order_dataframe['Order Date'].dt.month\n",
    "\n",
    "# Group by Order Month and count the number of orders\n",
    "orders_per_month = Order_dataframe.groupby('Order Month')['Order ID'].count()\n",
    "\n",
    "# Find the month with the highest number of orders\n",
    "most_important_month = orders_per_month\n",
    "print(f\"The most important month for orders is: {most_important_month}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The month with the highest average discount is: Order Month\n",
      "1     0.157037\n",
      "2     0.178889\n",
      "3     0.182143\n",
      "4     0.163551\n",
      "5     0.187267\n",
      "6     0.191310\n",
      "7     0.166463\n",
      "8     0.183790\n",
      "9     0.154468\n",
      "10    0.190749\n",
      "11    0.171379\n",
      "12    0.173811\n",
      "Name: Discount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group by Order Month and calculate the mean discount\n",
    "average_discount_per_month = Order_dataframe.groupby('Order Month')['Discount'].mean()\n",
    "\n",
    "# Find the month with the highest average discount\n",
    "most_discounted_month = average_discount_per_month\n",
    "print(f\"The month with the highest average discount is: {most_discounted_month}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most profitable month is: Order Month\n",
      "1    -1944.2130\n",
      "2      693.5796\n",
      "3      771.9875\n",
      "4     1460.3261\n",
      "5     2302.2981\n",
      "6      982.3847\n",
      "7     1412.6846\n",
      "8        4.0941\n",
      "9     5460.0023\n",
      "10   -3027.9321\n",
      "11    3920.0007\n",
      "12    6416.0602\n",
      "Name: Profit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group by Order Month and sum the Profit\n",
    "profit_per_month = Order_dataframe.groupby('Order Month')['Profit'].sum()\n",
    "\n",
    "# Find the month with the highest profit\n",
    "most_profitable_month = profit_per_month\n",
    "print(f\"The most profitable month is: {most_profitable_month}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Consumer' 'Corporate' 'Home Office']\n"
     ]
    }
   ],
   "source": [
    "unique_segments = Customer_dataframe['Segment'].unique()\n",
    "print(unique_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States']\n"
     ]
    }
   ],
   "source": [
    "unique_countries = Customer_dataframe['Country'].unique()\n",
    "print(unique_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "Customer_dataframe = Customer_dataframe.drop(columns=['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment\n",
      "Consumer       6991.0786\n",
      "Corporate      7584.8158\n",
      "Home Office    3875.3784\n",
      "Name: Profit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "profit_per_segment = Customer_dataframe.groupby('Segment')['Profit'].sum()\n",
    "print(profit_per_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The state with the most sales is: California with sales of 156064.6015\n"
     ]
    }
   ],
   "source": [
    "sales_per_state = Customer_dataframe.groupby('State')['Sales'].sum()\n",
    "most_sales_state = sales_per_state.idxmax()\n",
    "most_sales_value = sales_per_state.max()\n",
    "print(f\"The state with the most sales is: {most_sales_state} with sales of {most_sales_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ship Mode     First Class  Same Day  Second Class  Standard Class\n",
      "Sub-Category                                                     \n",
      "Bookcases              49         7            48             124\n",
      "Chairs                 85        39           134             359\n",
      "Furnishings           146        52           184             575\n",
      "Tables                 47        21            61             190\n"
     ]
    }
   ],
   "source": [
    "# Merge Product_dataframe and Order_dataframe on 'Row ID'\n",
    "merged_dataframe = pd.merge(Product_dataframe, Order_dataframe, on='Row ID')\n",
    "\n",
    "# Group by 'Sub-Category' and 'Ship Mode' and count the occurrences\n",
    "ship_mode_per_category = merged_dataframe.groupby(['Sub-Category', 'Ship Mode']).size().unstack(fill_value=0)\n",
    "print(ship_mode_per_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-Category          Bookcases  Chairs  Furnishings  Tables\n",
      "State                                                       \n",
      "Alabama                       0       5            3       3\n",
      "Arizona                       3      16           21       9\n",
      "Arkansas                      1       2            5       1\n",
      "California                   52     130          191      71\n",
      "Colorado                      9      14           24       4\n",
      "Connecticut                   2       3            6       2\n",
      "Delaware                      4       2           10       2\n",
      "District of Columbia          0       1            2       0\n",
      "Florida                       8      19           47      11\n",
      "Georgia                       5       6           19       2\n",
      "Idaho                         0       1            3       2\n",
      "Illinois                     10      38           57      18\n",
      "Indiana                       0       7           13       3\n",
      "Iowa                          0       1            2       1\n",
      "Kansas                        0       0            2       0\n",
      "Kentucky                      1      16           12       1\n",
      "Louisiana                     2       3            4       2\n",
      "Maine                         0       0            1       0\n",
      "Maryland                      3       8           15       2\n",
      "Massachusetts                 6       6           14       7\n",
      "Michigan                      4      21           18       7\n",
      "Minnesota                     0       6            5       2\n",
      "Mississippi                   1       1            5       2\n",
      "Missouri                      1       1            7       2\n",
      "Montana                       0       0            1       0\n",
      "Nebraska                      0       1            3       0\n",
      "Nevada                        1       1            5       2\n",
      "New Hampshire                 0       0            5       1\n",
      "New Jersey                    2       8           14       2\n",
      "New Mexico                    0       2            2       0\n",
      "New York                     32      76          100      28\n",
      "North Carolina                4      11           19       8\n",
      "Ohio                          8      23           46      16\n",
      "Oklahoma                      1       5            5       4\n",
      "Oregon                        3       8            5       5\n",
      "Pennsylvania                 10      36           64      15\n",
      "Rhode Island                  2       4            6       4\n",
      "South Carolina                0       3            3       0\n",
      "South Dakota                  1       1            0       0\n",
      "Tennessee                     2      13           22       8\n",
      "Texas                        27      61           81      33\n",
      "Utah                          2       0            3       2\n",
      "Vermont                       1       1            0       0\n",
      "Virginia                      4       9           26      13\n",
      "Washington                   10      34           49      21\n",
      "West Virginia                 0       0            0       1\n",
      "Wisconsin                     6      12           12       2\n",
      "Wyoming                       0       1            0       0\n"
     ]
    }
   ],
   "source": [
    "categories_per_state = dataframe.groupby(['State', 'Sub-Category']).size().unstack(fill_value=0)\n",
    "print(categories_per_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order_Type\n",
      "CA    3.905421\n",
      "US    3.968992\n",
      "Name: Shipping_Duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference in days between Order Date and Ship Date\n",
    "Order_dataframe['Shipping_Duration'] = (Order_dataframe['Ship Date'] - Order_dataframe['Order Date']).dt.days\n",
    "\n",
    "# Extract the order type (CA or US) from the Order ID\n",
    "Order_dataframe['Order_Type'] = Order_dataframe['Order ID'].str[:2]\n",
    "\n",
    "# Group by Order Type and calculate the average shipping duration\n",
    "average_shipping_duration = Order_dataframe.groupby('Order_Type')['Shipping_Duration'].mean()\n",
    "\n",
    "print(average_shipping_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shipping Duration Analysis\n",
    "\n",
    "The average shipping duration for orders with the `Order_Type` \"CA\" is approximately 3.91 days, while for \"US\" it is approximately 3.97 days. This minimal difference in shipping times indicates that there is no significant variation between the two order types. Therefore, we cannot draw a definitive conclusion about the meaning of the first two letters in the `Order ID` based on shipping duration alone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-Category   Bookcases      Chairs  Furnishings      Tables\n",
      "Segment                                                      \n",
      "Consumer      68632.7290  172862.742    49620.046  99933.7950\n",
      "Corporate     34005.9243   99140.878    25001.266  70871.7175\n",
      "Home Office   12241.3430   56445.483    17083.852  36160.0195\n",
      "Sub-Category  Bookcases      Chairs  Furnishings     Tables\n",
      "Segment                                                    \n",
      "Consumer     -4435.6382  13235.3319    7919.4227 -9728.0378\n",
      "Corporate      638.4502   8344.6565    3508.2077 -4906.4986\n",
      "Home Office    324.6320   5010.1779    1631.5132 -3090.9447\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Segment' and 'Sub-Category' and sum the Sales\n",
    "sales_per_segment_category = dataframe.groupby(['Segment', 'Sub-Category'])['Sales'].sum().unstack(fill_value=0)\n",
    "print(sales_per_segment_category)\n",
    "\n",
    "# Group by 'Segment' and 'Sub-Category' and sum the Profit\n",
    "profit_per_segment_category = dataframe.groupby(['Segment', 'Sub-Category'])['Profit'].sum().unstack(fill_value=0)\n",
    "print(profit_per_segment_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "# Key Takeaways from Data Exploration\n",
    "\n",
    "1. **Customer Segments**:\n",
    "    - The data includes three customer segments: Consumer, Corporate, and Home Office.\n",
    "    - Profit distribution across segments shows that Corporate customers are the most profitable, followed by Consumer and Home Office.\n",
    "\n",
    "2. **Product Categories**:\n",
    "    - The dataset contains four main product sub-categories: Bookcases, Chairs, Tables, and Furnishings.\n",
    "    - Chairs are the most profitable sub-category, while Tables have the highest negative profit, likely due to high discount rates.\n",
    "\n",
    "3. **Sales and Profit by State**:\n",
    "    - California is the state with the highest sales, amounting to approximately $156,064.60.\n",
    "    - Sales and profit vary significantly across different states, with some states showing negative profits.\n",
    "\n",
    "4. **Shipping Modes**:\n",
    "    - There are four shipping modes: Second Class, Standard Class, First Class, and Same Day.\n",
    "    - Standard Class is the most used shipping mode and also the most profitable.\n",
    "\n",
    "5. **Monthly Trends**:\n",
    "    - The month with the highest number of orders is December, followed by November.\n",
    "    - The most profitable month is December, while January shows a significant negative profit.\n",
    "\n",
    "6. **Discount Analysis**:\n",
    "    - The average discount varies by month, with June having the highest average discount.\n",
    "    - High discount rates on certain sub-categories, such as Tables and Bookcases, contribute to negative profits.\n",
    "\n",
    "7. **Order and Shipping Analysis**:\n",
    "    - The dataset includes detailed information on order dates, ship dates, and shipping modes.\n",
    "    - Grouping by order month and shipping mode provides insights into sales and profit trends over time.\n",
    "\n",
    "8. **Data Preparation**:\n",
    "    - The data has been split into three main dataframes: Order_dataframe, Customer_dataframe, and Product_dataframe for better analysis.\n",
    "    - Columns such as 'Category' have been dropped from the Product_dataframe to focus on sub-categories.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Although I could include various visualizations to represent the data graphically, I chose not to focus on them because I personally prefer working with textual data. This approach allows me to concentrate on the detailed analysis and insights derived from the data without the distraction of visual elements.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Order Date  Ship Date       Ship Mode   Segment Region Sub-Category  \\\n",
      "0 2016-11-08 2016-11-11    Second Class  Consumer  South    Bookcases   \n",
      "1 2016-11-08 2016-11-11    Second Class  Consumer  South       Chairs   \n",
      "2 2015-10-11 2015-10-18  Standard Class  Consumer  South       Tables   \n",
      "3 2014-06-09 2014-06-14  Standard Class  Consumer   West  Furnishings   \n",
      "4 2014-06-09 2014-06-14  Standard Class  Consumer   West       Tables   \n",
      "\n",
      "       Sales  Quantity  Discount    Profit  \n",
      "0   261.9600         2      0.00   41.9136  \n",
      "1   731.9400         3      0.00  219.5820  \n",
      "2   957.5775         5      0.45 -383.0310  \n",
      "3    48.8600         7      0.00   14.1694  \n",
      "4  1706.1840         9      0.20   85.3092  \n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['Row ID', 'Order ID', 'Customer ID', 'Product ID', 'Customer Name', 'Product Name', 'Country', 'City', 'State', 'Postal Code']\n",
    "dataframe = dataframe.drop(columns=columns_to_drop)\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Ship Mode    Segment   Region Sub-Category      Sales  Discount  \\\n",
      "1288     First Class  Corporate     West       Chairs   340.7040      0.20   \n",
      "197   Standard Class   Consumer  Central    Bookcases    78.8528      0.32   \n",
      "504   Standard Class  Corporate     West  Furnishings     7.4000      0.00   \n",
      "393   Standard Class   Consumer     West       Chairs   393.5680      0.20   \n",
      "1128  Standard Class   Consumer     West  Furnishings    68.4600      0.00   \n",
      "1619    Second Class   Consumer    South       Chairs   258.7500      0.00   \n",
      "1617    Second Class   Consumer    South       Chairs  1207.8400      0.00   \n",
      "1057  Standard Class  Corporate     West  Furnishings   101.1200      0.00   \n",
      "1618    Second Class   Consumer    South       Chairs   300.9800      0.00   \n",
      "186   Standard Class   Consumer     East    Bookcases   323.1360      0.20   \n",
      "\n",
      "      Quarter  \n",
      "1288        4  \n",
      "197         4  \n",
      "504         4  \n",
      "393         4  \n",
      "1128        4  \n",
      "1619        4  \n",
      "1617        4  \n",
      "1057        4  \n",
      "1618        4  \n",
      "186         4  \n",
      "Training data: (1696, 7)\n",
      "Testing data: (425, 7)\n"
     ]
    }
   ],
   "source": [
    "# Sort the dataframe by Order Date\n",
    "dataframe = dataframe.sort_values(by='Order Date')\n",
    "# Add Quarter column from the Order Date without the year\n",
    "dataframe['Quarter'] = dataframe['Order Date'].dt.quarter\n",
    "\n",
    "dataframe = dataframe.drop(columns=['Order Date', 'Ship Date'])\n",
    "\n",
    "dataframe = dataframe.drop(columns=['Profit', 'Quantity'])\n",
    "\n",
    "print(dataframe.tail(10))\n",
    "\n",
    "# Define the split point (e.g., 80% of the data for training and 20% for testing)\n",
    "split_point = int(len(dataframe) * 0.8)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = dataframe.iloc[:split_point]\n",
    "test_data = dataframe.iloc[split_point:]\n",
    "\n",
    "print(f\"Training data: {train_data.shape}\")\n",
    "print(f\"Testing data: {test_data.shape}\")\n",
    "\n",
    "# Save the training and testing data to CSV\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
